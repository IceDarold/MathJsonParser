# Kaggle Math Task Processor

Ноутбук для обработки математических задач на платформе Kaggle с использованием модели Qwen 2.5 7B.

## Быстрый старт

### 1. Создание нового ноутбука в Kaggle

1. Зайдите на [Kaggle](https://www.kaggle.com)
2. Создайте новый ноутбук (New Notebook)
3. Выберите GPU accelerator (обязательно!)

### 2. Загрузка файлов

Загрузите следующие файлы как Dataset в Kaggle:

**Обязательные файлы:**
- `test_private.csv` - файл с математическими задачами
- `llm_parser/prompts/system.txt` - системный промпт

**Как загрузить:**
1. В Kaggle перейдите в Data → New Dataset
2. Загрузите файлы
3. Назовите dataset, например "math-tasks-data"
4. Сделайте dataset публичным или приватным
5. В ноутбуке добавьте этот dataset как Input

### 3. Настройка HuggingFace токена

**Вариант 1 (Рекомендуемый) - Kaggle Secrets:**
1. В Kaggle перейдите в Account → Secrets
2. Добавьте новый secret:
   - Name: `HUGGINGFACE_API_TOKEN`
   - Value: ваш HuggingFace токен
3. В ноутбуке токен будет загружен автоматически

**Вариант 2 - Прямое указание:**
1. Получите токен на https://huggingface.co/settings/tokens
2. В ноутбуке замените строку:
   ```python
   HF_TOKEN = "your_huggingface_token_here"
   ```

### 4. Обновление путей к файлам

В ноутбуке обновите пути к вашим загруженным файлам:

```python
CSV_FILE = "/kaggle/input/math-tasks-data/test_private.csv"
SYSTEM_PROMPT_FILE = "/kaggle/input/math-tasks-data/system.txt"
```

### 5. Запуск

1. Скопируйте содержимое `kaggle_math_processor.ipynb` в ваш Kaggle ноутбук
2. Запустите все ячейки по порядку
3. Дождитесь завершения обработки

## Что делает ноутбук

1. **Устанавливает зависимости** - transformers, torch, accelerate, bitsandbytes
2. **Загружает модель Qwen 2.5 7B** с 4-bit квантизацией для экономии памяти
3. **Читает задачи** из CSV файла
4. **Обрабатывает каждую задачу** с системным промптом
5. **Сохраняет результаты** в JSON формате
6. **Создает отчет** о выполнении
7. **Упаковывает результаты** в ZIP архив для скачивания

## Структура выходных файлов

```
/kaggle/working/outputs/
├── individual/
│   ├── task_000001.json
│   ├── task_000002.json
│   └── ...
├── all_results_YYYYMMDD_HHMMSS.json
├── report_YYYYMMDD_HHMMSS.json
├── intermediate_results_010.json
├── intermediate_results_020.json
└── math_results_YYYYMMDD_HHMMSS.zip
```

## Технические особенности

### Оптимизация памяти:
- **4-bit квантизация** модели
- **Автоматическая очистка** памяти каждые 50 задач
- **Промежуточное сохранение** каждые 10 задач

### Обработка ошибок:
- **Автоматическое восстановление** при ошибках
- **Подробное логирование** всех операций
- **Сохранение частичных результатов**

### Производительность:
- **Ожидаемое время**: 2-4 часа для 344 задач
- **Скорость**: ~10-60 секунд на задачу
- **Требования GPU**: T4 или лучше

## Настройки модели

Можно изменить в коде:

```python
# Параметры генерации
max_new_tokens=2048,    # Максимальная длина ответа
temperature=0.1,        # Креативность (0.0-1.0)
top_p=0.9,             # Фильтрация токенов
do_sample=True         # Использовать сэмплирование
```

## Мониторинг прогресса

Ноутбук показывает:
- **Прогресс обработки** (X/344 tasks)
- **Время на задачу** для каждой задачи
- **Статус валидности JSON** для каждого ответа
- **Промежуточные сохранения** каждые 10 задач
- **Очистку памяти** каждые 50 задач

## Важные замечания

1. **GPU обязателен** - модель 7B требует GPU
2. **Время выполнения** - может занять несколько часов
3. **Kaggle лимиты** - учитывайте лимиты на время выполнения (9 часов)
4. **Сохранение результатов** - результаты сохраняются в `/kaggle/working/`
5. **Скачивание** - используйте созданный ZIP архив

## Решение проблем

**Ошибка памяти:**
- Уменьшите `max_new_tokens`
- Увеличьте частоту очистки памяти

**Медленная работа:**
- Проверьте, что включен GPU accelerator
- Убедитесь, что используется квантизация

**Ошибки токенизации:**
- Проверьте правильность HuggingFace токена
- Убедитесь, что токен имеет права на чтение

## Ожидаемые результаты

- **Формат**: JSON в соответствии с MathIR-JSON схемой
- **Содержание**: Структурированное представление математических задач
- **Качество**: Зависит от сложности задач и возможностей модели
- **Полнота**: Все 344 задачи будут обработаны