{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Task Processor for Kaggle\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Qwen 2.5 7B —á–µ—Ä–µ–∑ HuggingFace API.\n",
    "\n",
    "## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∑–∞–ø—É—Å–∫—É:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ Kaggle:**\n",
    "   - `test_private.csv` - —Ñ–∞–π–ª —Å –∑–∞–¥–∞—á–∞–º–∏\n",
    "   - `system.txt` - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n",
    "\n",
    "2. **–î–æ–±–∞–≤—å—Ç–µ HuggingFace —Ç–æ–∫–µ–Ω:**\n",
    "   - –í Kaggle Secrets –¥–æ–±–∞–≤—å—Ç–µ `HUGGINGFACE_API_TOKEN`\n",
    "   - –ò–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `HF_TOKEN` –≤ –∫–æ–¥–µ –Ω–∏–∂–µ\n",
    "\n",
    "3. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "!pip install transformers torch accelerate bitsandbytes pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import gc\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "CSV_FILE = \"/kaggle/input/aic-2025-math/test_private.csv\"  # –ü—É—Ç—å –∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É CSV —Ñ–∞–π–ª—É\n",
    "SYSTEM_PROMPT_FILE = \"/kaggle/input/aic-2025-math/system.txt\"  # –ü—É—Ç—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É\n",
    "OUTPUT_DIR = \"/kaggle/working/outputs\"\n",
    "\n",
    "# HuggingFace —Ç–æ–∫–µ–Ω (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Kaggle Secrets –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –Ω–∞–ø—Ä—è–º—É—é)\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    HF_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_API_TOKEN\")\n",
    "    print(\"‚úÖ HuggingFace token loaded from Kaggle Secrets\")\n",
    "except:\n",
    "    HF_TOKEN = \"your_huggingface_token_here\"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Ç–æ–∫–µ–Ω\n",
    "    print(\"‚ö†Ô∏è Using hardcoded token - consider using Kaggle Secrets\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞\n",
    "def load_system_prompt(file_path: str) -> str:\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è System prompt file not found: {file_path}\")\n",
    "        return \"\"\"–í–´ ‚Äî –°–¢–†–û–ì–ò–ô –ü–ê–†–°–ï–† –ú–ê–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ò–• –ó–ê–î–ê–ß.\n",
    "–í–∞—à–∞ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏ –≤ –≤–∞–ª–∏–¥–Ω—ã–π JSON —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ MathIR-JSON. \n",
    "–ù–ò–ö–û–ì–î–ê –Ω–µ —Ä–µ—à–∞–π—Ç–µ –∑–∞–¥–∞—á—É –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–∫—Ç—ã.\n",
    "–í–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ –¢–û–õ–¨–ö–û JSON. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, Markdown –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π.\"\"\"\n",
    "\n",
    "system_prompt = load_system_prompt(SYSTEM_PROMPT_FILE)\n",
    "print(f\"System prompt loaded: {len(system_prompt)} characters\")\n",
    "print(f\"First 100 chars: {system_prompt[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ CSV\n",
    "def load_tasks(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"‚úÖ Loaded {len(df)} tasks from {csv_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå CSV file not found: {csv_path}\")\n",
    "        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω\n",
    "        test_data = {\n",
    "            'task': [\n",
    "                '–í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–µ–¥–µ–ª: lim(x‚Üí0) sin(x)/x',\n",
    "                '–í—ã—á–∏—Å–ª–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞–ª: ‚à´‚ÇÄ^œÄ sin(x) dx',\n",
    "                '–ù–∞–π—Ç–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é: d/dx(x¬≤+2x+1)'\n",
    "            ]\n",
    "        }\n",
    "        df = pd.DataFrame(test_data)\n",
    "        print(f\"‚ö†Ô∏è Using test data: {len(df)} tasks\")\n",
    "        return df\n",
    "\n",
    "df = load_tasks(CSV_FILE)\n",
    "print(f\"Sample task: {df.iloc[0]['task'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏\n",
    "def setup_model():\n",
    "    \"\"\"–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å Qwen 2.5 7B —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π.\"\"\"\n",
    "    print(\"üîÑ Loading Qwen 2.5 7B model...\")\n",
    "    \n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=HF_TOKEN,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=HF_TOKEN,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Model loaded successfully\")\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤\n",
    "def generate_response(task: str, tokenizer, model, max_length: int = 2048) -> str:\n",
    "    \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á–∏.\"\"\"\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n",
    "    full_prompt = f\"{system_prompt}\\n\\n–ó–∞–¥–∞—á–∞: {task}\"\n",
    "    \n",
    "    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è Qwen\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"–ó–∞–¥–∞—á–∞: {task}\"}\n",
    "    ]\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º chat template\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.1,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞\n",
    "    response = tokenizer.decode(\n",
    "        outputs[0][inputs['input_ids'].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# –¢–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "test_task = \"–í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–µ–¥–µ–ª: lim(x‚Üí0) sin(x)/x\"\n",
    "print(\"üß™ Testing generation function...\")\n",
    "start_time = time.time()\n",
    "test_response = generate_response(test_task, tokenizer, model)\n",
    "test_time = time.time() - start_time\n",
    "print(f\"‚úÖ Test completed in {test_time:.2f}s\")\n",
    "print(f\"Response length: {len(test_response)} characters\")\n",
    "print(f\"First 200 chars: {test_response[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –∑–∞–¥–∞—á\n",
    "def process_all_tasks(df: pd.DataFrame, tokenizer, model) -> List[Dict[str, Any]]:\n",
    "    \"\"\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–∑ DataFrame.\"\"\"\n",
    "    results = []\n",
    "    total_tasks = len(df)\n",
    "    \n",
    "    print(f\"üöÄ Starting processing of {total_tasks} tasks...\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        task_id = f\"task_{index+1:06d}\"\n",
    "        task = row['task']\n",
    "        \n",
    "        print(f\"\\nüìù Processing {task_id} ({index+1}/{total_tasks})\")\n",
    "        print(f\"Task: {task[:100]}...\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = generate_response(task, tokenizer, model)\n",
    "            latency = time.time() - start_time\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            result = {\n",
    "                \"task_id\": task_id,\n",
    "                \"task\": task,\n",
    "                \"response\": response,\n",
    "                \"latency\": latency,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "            \n",
    "            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞\n",
    "            response_text = response.strip()\n",
    "            if response_text.startswith('{') and response_text.endswith('}'):\n",
    "                try:\n",
    "                    parsed_json = json.loads(response_text)\n",
    "                    result[\"parsed_json\"] = parsed_json\n",
    "                    print(f\"‚úÖ Valid JSON extracted\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"‚ö†Ô∏è Response looks like JSON but failed to parse\")\n",
    "            \n",
    "            results.append(result)\n",
    "            print(f\"‚úÖ {task_id} completed in {latency:.2f}s\")\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥—ã–µ 10 –∑–∞–¥–∞—á\n",
    "            if (index + 1) % 10 == 0:\n",
    "                save_intermediate_results(results, index + 1)\n",
    "                \n",
    "            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "            if (index + 1) % 50 == 0:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"üßπ Memory cleanup after {index + 1} tasks\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {task_id} failed: {str(e)}\")\n",
    "            result = {\n",
    "                \"task_id\": task_id,\n",
    "                \"task\": task,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_intermediate_results(results: List[Dict[str, Any]], count: int):\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\"\"\"\n",
    "    filename = f\"{OUTPUT_DIR}/intermediate_results_{count:03d}.json\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"üíæ Intermediate results saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á\n",
    "print(\"üöÄ Starting full processing...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = process_all_tasks(df, tokenizer, model)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nüéâ Processing completed in {total_time:.2f}s ({total_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "def save_final_results(results: List[Dict[str, Any]]):\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "    individual_dir = f\"{OUTPUT_DIR}/individual\"\n",
    "    os.makedirs(individual_dir, exist_ok=True)\n",
    "    \n",
    "    for result in results:\n",
    "        task_id = result[\"task_id\"]\n",
    "        with open(f\"{individual_dir}/{task_id}.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    all_results_file = f\"{OUTPUT_DIR}/all_results_{timestamp}.json\"\n",
    "    with open(all_results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç\n",
    "    successful = sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "    failed = len(results) - successful\n",
    "    total_latency = sum(r.get(\"latency\", 0) for r in results if \"latency\" in r)\n",
    "    avg_latency = total_latency / successful if successful > 0 else 0\n",
    "    \n",
    "    report = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_tasks\": len(results),\n",
    "        \"successful\": successful,\n",
    "        \"failed\": failed,\n",
    "        \"success_rate\": successful / len(results) if results else 0,\n",
    "        \"total_latency\": total_latency,\n",
    "        \"average_latency\": avg_latency,\n",
    "        \"model\": MODEL_NAME\n",
    "    }\n",
    "    \n",
    "    report_file = f\"{OUTPUT_DIR}/report_{timestamp}.json\"\n",
    "    with open(report_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nüìä Final Report:\")\n",
    "    print(f\"Total tasks: {report['total_tasks']}\")\n",
    "    print(f\"Successful: {report['successful']}\")\n",
    "    print(f\"Failed: {report['failed']}\")\n",
    "    print(f\"Success rate: {report['success_rate']:.2%}\")\n",
    "    print(f\"Average latency: {report['average_latency']:.2f}s\")\n",
    "    print(f\"\\nüíæ Files saved:\")\n",
    "    print(f\"- Individual results: {individual_dir}/\")\n",
    "    print(f\"- All results: {all_results_file}\")\n",
    "    print(f\"- Report: {report_file}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "final_report = save_final_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "def analyze_results(results: List[Dict[str, Any]]):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏.\"\"\"\n",
    "    print(\"üìà Results Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    successful_results = [r for r in results if r[\"status\"] == \"success\" and \"latency\" in r]\n",
    "    if successful_results:\n",
    "        latencies = [r[\"latency\"] for r in successful_results]\n",
    "        print(f\"‚è±Ô∏è Timing Statistics:\")\n",
    "        print(f\"  Min latency: {min(latencies):.2f}s\")\n",
    "        print(f\"  Max latency: {max(latencies):.2f}s\")\n",
    "        print(f\"  Avg latency: {sum(latencies)/len(latencies):.2f}s\")\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ JSON\n",
    "    json_results = [r for r in results if \"parsed_json\" in r]\n",
    "    print(f\"\\nüìã JSON Statistics:\")\n",
    "    print(f\"  Valid JSON responses: {len(json_results)}/{len(successful_results)}\")\n",
    "    print(f\"  JSON success rate: {len(json_results)/len(successful_results)*100:.1f}%\")\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫\n",
    "    error_results = [r for r in results if r[\"status\"] == \"error\"]\n",
    "    if error_results:\n",
    "        print(f\"\\n‚ùå Error Examples:\")\n",
    "        for i, error_result in enumerate(error_results[:3]):\n",
    "            print(f\"  {i+1}. {error_result['task_id']}: {error_result['error'][:100]}...\")\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n",
    "    if json_results:\n",
    "        print(f\"\\n‚úÖ JSON Response Examples:\")\n",
    "        for i, json_result in enumerate(json_results[:2]):\n",
    "            print(f\"  {i+1}. {json_result['task_id']}:\")\n",
    "            print(f\"     Task: {json_result['task'][:80]}...\")\n",
    "            print(f\"     JSON keys: {list(json_result['parsed_json'].keys())}\")\n",
    "\n",
    "analyze_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è\n",
    "import zipfile\n",
    "\n",
    "def create_download_archive():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç ZIP –∞—Ä—Ö–∏–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f\"{OUTPUT_DIR}/math_results_{timestamp}.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "        for root, dirs, files in os.walk(OUTPUT_DIR):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, OUTPUT_DIR)\n",
    "                    zipf.write(file_path, arcname)\n",
    "    \n",
    "    print(f\"üì¶ Archive created: {archive_name}\")\n",
    "    print(f\"üìÅ Archive size: {os.path.getsize(archive_name) / 1024 / 1024:.2f} MB\")\n",
    "    return archive_name\n",
    "\n",
    "archive_path = create_download_archive()\n",
    "print(f\"\\nüéØ Download your results: {archive_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PROCESSING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Summary:\")\n",
    "print(f\"  ‚Ä¢ Total tasks processed: {len(results)}\")\n",
    "print(f\"  ‚Ä¢ Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"  ‚Ä¢ Failed: {sum(1 for r in results if r['status'] == 'error')}\")\n",
    "print(f\"  ‚Ä¢ Success rate: {sum(1 for r in results if r['status'] == 'success')/len(results)*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Total time: {sum(r.get('latency', 0) for r in results)/60:.1f} minutes\")\n",
    "print(f\"\\nüìÅ Output files:\")\n",
    "print(f\"  ‚Ä¢ Individual JSON files: {OUTPUT_DIR}/individual/\")\n",
    "print(f\"  ‚Ä¢ Combined results: {OUTPUT_DIR}/all_results_*.json\")\n",
    "print(f\"  ‚Ä¢ Processing report: {OUTPUT_DIR}/report_*.json\")\n",
    "print(f\"  ‚Ä¢ Download archive: {archive_path}\")\n",
    "print(f\"\\nüîß Model used: {MODEL_NAME}\")\n",
    "print(f\"üìù System prompt: {len(system_prompt)} characters\")\n",
    "print(\"\\n‚úÖ All tasks completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
